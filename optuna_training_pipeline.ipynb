{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T13:09:46.763305Z","iopub.execute_input":"2025-12-25T13:09:46.763741Z","iopub.status.idle":"2025-12-25T13:09:47.046275Z","shell.execute_reply.started":"2025-12-25T13:09:46.763710Z","shell.execute_reply":"2025-12-25T13:09:47.045605Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/main_training_data_optimized.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T13:09:50.950863Z","iopub.execute_input":"2025-12-25T13:09:50.951733Z","iopub.status.idle":"2025-12-25T13:09:56.496621Z","shell.execute_reply.started":"2025-12-25T13:09:50.951691Z","shell.execute_reply":"2025-12-25T13:09:56.496000Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/dataset/main_training_data_optimized.csv\"\n\ndf = pd.read_csv(DATA_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T13:10:02.550310Z","iopub.execute_input":"2025-12-25T13:10:02.551124Z","iopub.status.idle":"2025-12-25T13:10:38.450922Z","shell.execute_reply.started":"2025-12-25T13:10:02.551096Z","shell.execute_reply":"2025-12-25T13:10:38.450293Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"y = df[\"target\"].astype(np.int8)\nuser_ids = df[\"user_id\"]\n\nX = df.drop(columns=[\"target\", \"user_id\"])\nX = X.astype(np.float32)\n\nunique_users = user_ids.unique()\n\ntrain_users, val_users = train_test_split(\n    unique_users,\n    test_size=0.2,\n    random_state=42\n)\n\ntrain_mask = user_ids.isin(train_users)\nval_mask   = user_ids.isin(val_users)\n\nX_train = X[train_mask]\nX_val   = X[val_mask]\n\ny_train = y[train_mask]\ny_val   = y[val_mask]\n\nassert set(user_ids[train_mask]).isdisjoint(set(user_ids[val_mask]))\n\nprint(\"Train rows:\", X_train.shape)\nprint(\"Val rows:\", X_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T13:37:48.624508Z","iopub.execute_input":"2025-12-25T13:37:48.625435Z","iopub.status.idle":"2025-12-25T13:37:52.436862Z","shell.execute_reply.started":"2025-12-25T13:37:48.625407Z","shell.execute_reply":"2025-12-25T13:37:52.436108Z"}},"outputs":[{"name":"stdout","text":"Train rows: (10627766, 25)\nVal rows: (2680187, 25)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def objective(trial):\n\n    model_type = trial.suggest_categorical(\n        \"model_type\", [\"lightgbm\", \"xgboost\", \"catboost\"]\n    )\n\n    # =====================\n    # LIGHTGBM \n    # =====================\n    if model_type == \"lightgbm\":\n\n        params = {\n            \"objective\": \"binary\",\n            \"metric\": \"auc\",\n            \"boosting_type\": \"gbdt\",\n            \"verbosity\": -1,\n\n            \"learning_rate\": trial.suggest_float(\"lgb_lr\", 0.01, 0.08),\n            \"num_leaves\": trial.suggest_int(\"lgb_num_leaves\", 32, 128),\n            \"max_depth\": trial.suggest_int(\"lgb_max_depth\", 5, 12),\n            \"min_child_samples\": trial.suggest_int(\"lgb_min_child\", 20, 150),\n            \"feature_fraction\": trial.suggest_float(\"lgb_feature_frac\", 0.6, 1.0),\n            \"bagging_fraction\": trial.suggest_float(\"lgb_bagging_frac\", 0.6, 1.0),\n            \"bagging_freq\": trial.suggest_int(\"lgb_bagging_freq\", 1, 7),\n            \"lambda_l1\": trial.suggest_float(\"lgb_l1\", 0.0, 5.0),\n            \"lambda_l2\": trial.suggest_float(\"lgb_l2\", 0.0, 5.0),\n\n            # CUDA\n            \"device\": \"gpu\",\n            \"gpu_platform_id\": 0,\n            \"gpu_device_id\": 0,\n        }\n\n        train_data = lgb.Dataset(X_train, label=y_train)\n        valid_data = lgb.Dataset(X_val, label=y_val)\n\n        model = lgb.train(\n            params,\n            train_data,\n            valid_sets=[valid_data],\n            num_boost_round=1400,\n            callbacks=[\n                lgb.early_stopping(30),\n                lgb.log_evaluation(0),\n            ],\n        )\n\n        preds = model.predict(X_val)\n        return roc_auc_score(y_val, preds)\n\n    # =====================\n    # XGBOOST \n    # =====================\n    elif model_type == \"xgboost\":\n\n        model = xgb.XGBClassifier(\n            objective=\"binary:logistic\",\n            eval_metric=\"auc\",\n            tree_method=\"gpu_hist\",\n            predictor=\"gpu_predictor\",\n\n            learning_rate=trial.suggest_float(\"xgb_lr\", 0.01, 0.08),\n            max_depth=trial.suggest_int(\"xgb_max_depth\", 4, 10),\n            min_child_weight=trial.suggest_float(\"xgb_min_child\", 1, 15),\n            subsample=trial.suggest_float(\"xgb_subsample\", 0.6, 1.0),\n            colsample_bytree=trial.suggest_float(\"xgb_colsample\", 0.6, 1.0),\n            gamma=trial.suggest_float(\"xgb_gamma\", 0.0, 5.0),\n            reg_lambda=trial.suggest_float(\"xgb_lambda\", 0.0, 5.0),\n            reg_alpha=trial.suggest_float(\"xgb_alpha\", 0.0, 5.0),\n\n            n_estimators=1400,\n            early_stopping_rounds=30,\n            verbosity=0,\n        )\n\n        model.fit(\n            X_train,\n            y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=False\n        )\n\n        preds = model.predict_proba(X_val)[:, 1]\n        return roc_auc_score(y_val, preds)\n\n    # =====================\n    # CATBOOST \n    # =====================\n    else:\n\n        model = CatBoostClassifier(\n            loss_function=\"Logloss\",\n            eval_metric=\"AUC\",\n            task_type=\"GPU\",\n            devices=\"0\",\n\n            learning_rate=trial.suggest_float(\"cat_lr\", 0.01, 0.08),\n            depth=trial.suggest_int(\"cat_depth\", 4, 9),\n            l2_leaf_reg=trial.suggest_float(\"cat_l2\", 1.0, 8.0),\n            random_strength=trial.suggest_float(\"cat_rand\", 0.0, 2.0),\n            bagging_temperature=trial.suggest_float(\"cat_bag\", 0.0, 1.0),\n\n            iterations=1400,\n            early_stopping_rounds=30,\n            verbose=False,\n        )\n\n        model.fit(X_train, y_train, eval_set=(X_val, y_val))\n        preds = model.predict_proba(X_val)[:, 1]\n        return roc_auc_score(y_val, preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T13:38:29.247325Z","iopub.execute_input":"2025-12-25T13:38:29.247667Z","iopub.status.idle":"2025-12-25T13:38:29.258119Z","shell.execute_reply.started":"2025-12-25T13:38:29.247641Z","shell.execute_reply":"2025-12-25T13:38:29.257444Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T13:38:35.922746Z","iopub.execute_input":"2025-12-25T13:38:35.922999Z","iopub.status.idle":"2025-12-25T14:40:42.342552Z","shell.execute_reply.started":"2025-12-25T13:38:35.922981Z","shell.execute_reply":"2025-12-25T14:40:42.341524Z"}},"outputs":[{"name":"stderr","text":"[I 2025-12-25 13:38:35,924] A new study created in memory with name: no-name-051281de-b138-4e25-bdd4-22379bbef0b3\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[290]\tvalid_0's auc: 0.817641\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-12-25 13:42:16,683] Trial 0 finished with value: 0.8176408807855196 and parameters: {'model_type': 'lightgbm', 'lgb_lr': 0.0741187913684347, 'lgb_num_leaves': 46, 'lgb_max_depth': 10, 'lgb_min_child': 25, 'lgb_feature_frac': 0.7005400647527783, 'lgb_bagging_frac': 0.8291462375780057, 'lgb_bagging_freq': 1, 'lgb_l1': 1.7536357783869132, 'lgb_l2': 4.689166529732533}. Best is trial 0 with value: 0.8176408807855196.\n[I 2025-12-25 13:42:50,522] Trial 1 finished with value: 0.8176522023525037 and parameters: {'model_type': 'xgboost', 'xgb_lr': 0.06880111614104577, 'xgb_max_depth': 9, 'xgb_min_child': 8.454647783815767, 'xgb_subsample': 0.9804881873202625, 'xgb_colsample': 0.9121038888272348, 'xgb_gamma': 1.4103678523324699, 'xgb_lambda': 1.5551012624765004, 'xgb_alpha': 4.021558336739586}. Best is trial 1 with value: 0.8176522023525037.\n[I 2025-12-25 13:43:51,795] Trial 2 finished with value: 0.8177984973954346 and parameters: {'model_type': 'xgboost', 'xgb_lr': 0.03337850981638362, 'xgb_max_depth': 7, 'xgb_min_child': 3.324284134597157, 'xgb_subsample': 0.6611145273160108, 'xgb_colsample': 0.6347315651455999, 'xgb_gamma': 4.143859170908512, 'xgb_lambda': 3.2258138253115765, 'xgb_alpha': 4.521525694487455}. Best is trial 2 with value: 0.8177984973954346.\nDefault metric period is 5 because AUC is/are not implemented for GPU\n[I 2025-12-25 13:45:37,149] Trial 3 finished with value: 0.8173416692558481 and parameters: {'model_type': 'catboost', 'cat_lr': 0.05402285769606037, 'cat_depth': 4, 'cat_l2': 2.795565433731208, 'cat_rand': 0.5285502069804242, 'cat_bag': 0.8060610241328972}. Best is trial 2 with value: 0.8177984973954346.\nDefault metric period is 5 because AUC is/are not implemented for GPU\n[I 2025-12-25 13:47:00,806] Trial 4 finished with value: 0.8170778572051727 and parameters: {'model_type': 'catboost', 'cat_lr': 0.03020142123847061, 'cat_depth': 4, 'cat_l2': 4.796810076430122, 'cat_rand': 0.6511414381346978, 'cat_bag': 0.6673957818805893}. Best is trial 2 with value: 0.8177984973954346.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[807]\tvalid_0's auc: 0.817844\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-12-25 13:57:43,302] Trial 5 finished with value: 0.8178440685367452 and parameters: {'model_type': 'lightgbm', 'lgb_lr': 0.020524119954249836, 'lgb_num_leaves': 62, 'lgb_max_depth': 7, 'lgb_min_child': 68, 'lgb_feature_frac': 0.7048511951639247, 'lgb_bagging_frac': 0.8216334105118741, 'lgb_bagging_freq': 1, 'lgb_l1': 0.5067095801454502, 'lgb_l2': 4.219106216405748}. Best is trial 5 with value: 0.8178440685367452.\nDefault metric period is 5 because AUC is/are not implemented for GPU\n[I 2025-12-25 13:59:06,444] Trial 6 finished with value: 0.8173645101096774 and parameters: {'model_type': 'catboost', 'cat_lr': 0.0485835800634149, 'cat_depth': 4, 'cat_l2': 5.064559290631564, 'cat_rand': 1.8350810579242367, 'cat_bag': 0.3449204827705107}. Best is trial 5 with value: 0.8178440685367452.\n[I 2025-12-25 13:59:52,101] Trial 7 finished with value: 0.8177430564258055 and parameters: {'model_type': 'xgboost', 'xgb_lr': 0.03495021044346388, 'xgb_max_depth': 10, 'xgb_min_child': 4.510991693318454, 'xgb_subsample': 0.9965497565564277, 'xgb_colsample': 0.8502104967634463, 'xgb_gamma': 3.266103075774759, 'xgb_lambda': 4.250288629370688, 'xgb_alpha': 2.2533624470326035}. Best is trial 5 with value: 0.8178440685367452.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[259]\tvalid_0's auc: 0.817758\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-12-25 14:05:09,865] Trial 8 finished with value: 0.8177582823508418 and parameters: {'model_type': 'lightgbm', 'lgb_lr': 0.058073780061666073, 'lgb_num_leaves': 96, 'lgb_max_depth': 8, 'lgb_min_child': 33, 'lgb_feature_frac': 0.6520504745293689, 'lgb_bagging_frac': 0.7074275234305818, 'lgb_bagging_freq': 2, 'lgb_l1': 2.552136431498635, 'lgb_l2': 1.4316823986695681}. Best is trial 5 with value: 0.8178440685367452.\nDefault metric period is 5 because AUC is/are not implemented for GPU\n[I 2025-12-25 14:06:42,472] Trial 9 finished with value: 0.8167634345191336 and parameters: {'model_type': 'catboost', 'cat_lr': 0.012994716080374065, 'cat_depth': 5, 'cat_l2': 6.529860823701608, 'cat_rand': 0.2743465173975048, 'cat_bag': 0.2615363023742804}. Best is trial 5 with value: 0.8178440685367452.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[1208]\tvalid_0's auc: 0.817701\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-12-25 14:26:07,036] Trial 10 finished with value: 0.8177012603629761 and parameters: {'model_type': 'lightgbm', 'lgb_lr': 0.011502367770731228, 'lgb_num_leaves': 54, 'lgb_max_depth': 6, 'lgb_min_child': 123, 'lgb_feature_frac': 0.9417666817196498, 'lgb_bagging_frac': 0.9780293237958657, 'lgb_bagging_freq': 7, 'lgb_l1': 0.1393826754107778, 'lgb_l2': 4.159270452600119}. Best is trial 5 with value: 0.8178440685367452.\n[I 2025-12-25 14:28:11,405] Trial 11 finished with value: 0.817495729233457 and parameters: {'model_type': 'xgboost', 'xgb_lr': 0.01079076500451347, 'xgb_max_depth': 5, 'xgb_min_child': 1.0742458230444019, 'xgb_subsample': 0.6024942310404537, 'xgb_colsample': 0.6063331357559586, 'xgb_gamma': 4.837176794828675, 'xgb_lambda': 3.6837187755725163, 'xgb_alpha': 4.873199435895291}. Best is trial 5 with value: 0.8178440685367452.\n[I 2025-12-25 14:29:07,659] Trial 12 finished with value: 0.817760166139395 and parameters: {'model_type': 'xgboost', 'xgb_lr': 0.04016603329919731, 'xgb_max_depth': 6, 'xgb_min_child': 14.526981537766023, 'xgb_subsample': 0.6488015185828302, 'xgb_colsample': 0.6223615883911318, 'xgb_gamma': 4.181014437403156, 'xgb_lambda': 0.15595025109139815, 'xgb_alpha': 0.08015489080321192}. Best is trial 5 with value: 0.8178440685367452.\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 30 rounds\n","output_type":"stream"},{"name":"stderr","text":"[W 2025-12-25 14:40:42,173] Trial 13 failed with parameters: {'model_type': 'lightgbm', 'lgb_lr': 0.018330883405237582, 'lgb_num_leaves': 121, 'lgb_max_depth': 5, 'lgb_min_child': 90, 'lgb_feature_frac': 0.812185800672158, 'lgb_bagging_frac': 0.8441377450354582, 'lgb_bagging_freq': 4, 'lgb_l1': 4.889415161405484, 'lgb_l2': 3.098470276617171} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/tmp/ipykernel_47/378875036.py\", line 37, in objective\n    model = lgb.train(\n            ^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py\", line 322, in train\n    booster.update(fobj=fobj)\n  File \"/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\", line 4155, in update\n    _LIB.LGBM_BoosterUpdateOneIter(\nKeyboardInterrupt\n[W 2025-12-25 14:40:42,176] Trial 13 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1344980342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     ):\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/378875036.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         model = lgb.train(\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4153\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot update due to null objective function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m             _safe_call(\n\u001b[0;32m-> 4155\u001b[0;31m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   4156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4157\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"print(\"BEST AUC:\", study.best_value)\nprint(\"BEST PARAMS:\")\nfor k, v in study.best_params.items():\n    print(f\"{k}: {v}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T14:43:01.596948Z","iopub.execute_input":"2025-12-25T14:43:01.597238Z","iopub.status.idle":"2025-12-25T14:43:01.602089Z","shell.execute_reply.started":"2025-12-25T14:43:01.597214Z","shell.execute_reply":"2025-12-25T14:43:01.601471Z"}},"outputs":[{"name":"stdout","text":"BEST AUC: 0.8178440685367452\nBEST PARAMS:\nmodel_type: lightgbm\nlgb_lr: 0.020524119954249836\nlgb_num_leaves: 62\nlgb_max_depth: 7\nlgb_min_child: 68\nlgb_feature_frac: 0.7048511951639247\nlgb_bagging_frac: 0.8216334105118741\nlgb_bagging_freq: 1\nlgb_l1: 0.5067095801454502\nlgb_l2: 4.219106216405748\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}